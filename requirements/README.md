# Requirement structure

## Background

Boardfarm, with the standardization of the test interface, supports an highly efficient process to automate test cases. In this section we are proposing a structure to capture the system requirements in a way to:

1. clearly link the test cases to the requirements
2. capture the requirements in a git-friendly format
3. maximize the efficiency of converting the requirement to automated test cases
4. facilitate automated checks in terms of requirements coverage

**PLEASE NOTE:**  
The below is an suggestion to organize requirement and test cases.
Most of the test cases listed in this repository are not (yet) linked to requirements in the way it is suggested here. The Requiremnt Use cases and the assocated tests are examples of how this could be done. The associanted automated test cases have been generated by (with the help of) AI.

## Link test cases to requirements

Requirements lead the definition of how the system should behave and is the result of the collaboration of many stakeholders, In order to have a traceable understanding as to how well the test suite is covering the system requirements, it makes sense to link the two.

### Traceability through Pytest Markers

To create a direct link between a use case scenario and the code that tests it, we use `pytest` markers. This allows for precise traceability and the ability to selectively run tests based on requirements.

**1. Marker Naming Convention**

Markers are named with a convention that includes the use case ID and the specific scenario being tested:

`@pytest.mark.uc<ID>_<scenario>`

-   `<ID>`: The identifier of the use case (e.g., `12345`).
-   `<scenario>`: The scenario covered by the test.
    -   `main`: For the main success scenario.
    -   `ext_<step>`: For an extension, where `<step>` is the step number from the use case document (e.g., `ext_2a`).

**Example Markers:**

-   `@pytest.mark.uc12345_main`
-   `@pytest.mark.uc12345_ext_4a`

**2. Marker Registration**

All custom markers must be registered to avoid warnings and ensure they are discoverable. This is done in the `pyproject.toml` file under the `[tool.pytest.ini_options]` section.

```toml
[tool.pytest.ini_options]
markers = [
    "uc12345_main: Test case for the main success scenario of UC-12345",
    "uc12345_ext_2a: Test case for extension 2.a of UC-12345",
    # ... and so on for other scenarios
]
```

**3. Applying Markers to Tests**

To tag a test function, apply the corresponding marker directly above the function definition:

```python
@pytest.mark.uc12345_main
def test_cpe_upgrade_preserve_settings():
    """
    This test covers the main success scenario for the CPE firmware upgrade.
    """
    # ... test implementation ...
```

**4. Running Tagged Tests**

You can execute a specific set of tests using the `-m` flag in `pytest`:

```bash
# Run all tests for the main success scenario of UC-12345
pytest -m uc12345_main

# Run all tests related to any scenario in UC-12345
pytest -m "uc12345"
```

This approach provides a robust and clear method for ensuring that our test suite accurately reflects the documented system requirements.

## Test Suite Structure and Naming Convention

To ensure the test suite is well-organized, maintainable, and easy to navigate, we adopt a standardized structure based on the use cases.

### Guiding Principles

-   **Group by Use Case:** All tests related to a single use case (including its main success scenario and all extensions) should be located in the same test file. This improves code reusability for fixtures and helper functions and makes it easy to find all relevant tests for a feature.
-   **Clarity at a Glance:** The naming of files and functions should clearly communicate what feature and what specific behavior are under test.

### Naming Convention

We use a three-tiered approach to link a test to a requirement:

1.  **File Name:** Uniquely identifies the use case.
    -   **Format:** `test_<use_case_id>_<short_description>.py`
    -   **Example:** `test_uc12345_cpe_upgrade.py`

2.  **Test Function Name:** Describes the specific scenario being tested.
    -   **Format:** `test_<scenario_description>`
    -   **Example:** `test_main_scenario_settings_preserved`
    -   **Example:** `test_ext_4a_rollback_on_connection_failure`

3.  **Pytest Marker:** Provides the formal, machine-readable link to the requirement scenario for traceability and selective test execution. (See "Traceability through Pytest Markers" for more detail).
    -   **Example:** `@pytest.mark.uc12345_main`

This structure creates a clear and logical mapping from high-level requirements down to the specific lines of code that verify them.

## Capture requirements in a git-friendly format

Requirements need, just like software, a solid version control system. By using Git as a version control system for requiremtns, it is possible to mange the requrements in the same repositories as the software development team. This increases the collaboration between the product management and engineering teams, and allows the documentation of every release to be up to date.
The proposal is to write requirements in Markdown text files as this formate is highly portable and accessible by many different editors. (VSCode, Cursor, Obsidian, etc.)

## Maximize efficiency in generating automated test cases

By defining clear and complete descriptions as to how the system is to behave, it is possible to utilize LLM's to expedite the translation of these scenarios into scripts that leverage the standardized test interface defined by Boardfarm.
Please see a [use case template](Use Case Template (reflect the goal).md) as a possible way to accomplish this.
The template is based on the excellent work by Alistair Cockburn: "Writing Effective Use Cases"

## Facilitate automated checks in terms of requirements coverage

This is also enabled by the structured approach in defining how the system should behave and the interpretation of the functionality verified by the associated tests. The file formats and the definition of the standardized test interface allow for a very efficiently verification process with the use of LLM's

## Use case structure for requirements

Each use case should have the following elements:

| Paragraph title                     | Intended content                                                                                                                                                                                                        |
| ----------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Use case name and goal              | A clear and short descriptor indicating what the goal of the use case is - should also be reflected in the name of the use case file                                                                                    |
| Primary Actor                       | Specifies who the primary actor is trying the achieve the goal                                                                                                                                                          |
| Stakeholders                        | Identifies the other stakeholders having an interest in the the use case                                                                                                                                                |
| Level                               | The level of the use case: summary, user-goal or sub-function                                                                                                                                                           |
| Preconditions                       | What we expect is already the state of the world                                                                                                                                                                        |
| Minimal Guarantees                  | How the interests of all actors and stakeholders are protected under all exits of the use case                                                                                                                          |
| Success Guarantees                  | The state of the world if the goal of the use case is achieved                                                                                                                                                          |
| Trigger                             | What starts the use-case - could be a time-trigger as well as an action by an actor.                                                                                                                                    |
| Main Success Scenario               | List of steps from trigger to goal delivery and any cleanup after                                                                                                                                                       |
| Extensions                          | *Optional:* List of extensions referencing the relevant step in the main scenario<br>Also possible to list extensions on extensions - be careful not to extend too deeply; use reference to a separate use-case instead |
| Technology and Data variations list | *Optional:* Put here the variations that will cause eventual bifurcation in the scenario                                                                                                                                |
| Related information                 | *Optional:* Any additional information related to the use case needed.                                                                                                                                                  |
